spark.executor.cores=${env.sparkmr3.sparkWorkerCores}
spark.executor.memory=${env.sparkmr3.workerMemoryInMb}m
spark.executor.memoryOverhead=${env.sparkmr3.workerMemoryOverheadInMb}m
spark.task.cpus=${env.sparkmr3.sparkTaskCpus}

spark.shuffle.service.enabled=${env.sparkmr3.useShuffleHandlerProcess}
spark.shuffle.service.port=7337
spark.mr3.use.daemon.shufflehandler=${env.sparkmr3.useDaemonShuffleHandler}
spark.mr3.k8s.shuffle.process.ports=7337

spark.mr3.client.connect.timeout.ms=30000
spark.mr3.dag.status.checker.period.ms=1000

spark.sql.legacy.createHiveTableByDefault=false
spark.sql.sources.default=orc

spark.hadoop.fs.s3a.bucket.all.committer.magic.enabled=true
spark.hadoop.fs.s3a.directory.marker.retention=keep

spark.shuffle.io.serverThreads=1
spark.shuffle.io.clientThreads=1
spark.shuffle.io.numConnectionsPerPeer=1

spark.hadoop.ipc.maximum.data.length=1073741824

spark.local.dir=${env.basics.mr3WorkerHostPaths}

