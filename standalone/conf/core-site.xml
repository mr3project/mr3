<configuration>

<!-- Local directory for temporary files -->
<property>
  <name>hadoop.tmp.dir</name>
  <value>/tmp/${user.name}</value>
</property>

<property>
  <name>fs.defaultFS</name>
  <value>file:///</value>
</property>

<property>
  <name>io.file.buffer.size</name>
  <value>131072</value>
</property>

<property>
  <name>io.serializations</name>
  <value>org.apache.hadoop.io.serializer.WritableSerialization</value>
</property>

<property>
  <name>hadoop.security.authentication</name>
  <value>simple</value>
</property>

<property>
  <name>ipc.client.fallback-to-simple-auth-allowed</name>
  <value>true</value>
</property>

<!-- Cf. tez.runtime.shuffle.ssl.enable for secure shuffle in tez-site.xml -->
<property>
  <name>hadoop.security.credential.provider.path</name>
  <value></value>
  <!-- <value>localjceks://file/${base.key.dir}/hivemr3-ssl-certificate.jceks</value> -->
</property>

<!-- S3 -->

<!-- set when using S3 or on AWS EKS -->
<!-- options:
     com.amazonaws.auth.EnvironmentVariableCredentialsProvider
     com.amazonaws.auth.InstanceProfileCredentialsProvider
     com.amazonaws.auth.WebIdentityTokenCredentialsProvider -->
<property>
  <name>fs.s3a.aws.credentials.provider</name>
  <value></value>
</property>

<property>
  <name>fs.s3a.connection.ssl.enabled</name>
  <value>false</value>
</property>

<!-- do not set on AWS EKS -->
<property>
  <name>fs.s3a.endpoint</name>
  <value></value>
</property>

<!-- set to true when using path-style access to S3-compliant storage -->
<property>
  <name>fs.s3a.path.style.access</name>
  <value>true</value>
</property>

<property>
  <name>fs.s3a.impl</name>
  <value>org.apache.hadoop.fs.s3a.S3AFileSystem</value>
</property>

<property>
  <name>fs.s3a.connection.maximum</name>
  <value>4000</value>
</property>

<property>
  <name>fs.s3.maxConnections</name>
  <value>4000</value>
</property>

<property>
  <name>fs.s3a.threads.max</name>
  <value>250</value>
</property>

<property>
  <name>fs.s3a.threads.core</name>
  <value>250</value>
</property>

<!-- S3 write performance -->

<property>
  <name>hive.mv.files.thread</name>
  <value>15</value>
</property>

<property>
  <name>fs.s3a.max.total.tasks</name>
  <value>5</value>
</property>

<property>
  <name>fs.s3a.blocking.executor.enabled</name>
  <value>false</value>
</property>

<!-- with HIVE-21390, the # of InputSplits is affected by hive.exec.orc.blob.storage.split.size
     when hive.exec.orc.split.strategy is set to BI -->
<property>
  <name>fs.s3a.block.size</name>
  <value>128M</value>
</property>

<!-- S3 input listing (Cf. hive.exec.input.listing.max.threads) -->
<property>
  <name>mapreduce.input.fileinputformat.list-status.num-threads</name>
  <value>50</value>
</property>

<!-- ORC 2 -->

<property>
  <name>fs.s3a.vectored.read.min.seek.size</name>
  <value>512K</value>
</property>

<property>
  <name>fs.s3a.vectored.read.max.merged.size</name>
  <value>4M</value>
</property>

</configuration>
